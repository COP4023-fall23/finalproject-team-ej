{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analysis project<h1>\n",
    "<h3>Name student: Ennis McCorvey IV<h3>\n",
 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [

#Data Wrangling

file_path = 'customer_reviewers.tsv'
reviewers_df = pd.read_csv('customer_reviewers.tsv',sep='\t')
print(reviewers_df.head(10))


# Check for missing values in the entire DataFrame
print(" Checking for missing values ")
print(reviewers_df.isnull().sum())
miss_rows = reviewers_df[reviewers_df.isnull().any(axis=1)]
print(miss_rows)

#Removing Stopwords
def remove_stopwords(review):
    stop_words = set(stopwords.words('english'))
    word_tokens = word_tokenize(review)
    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]
    return ' '.join(filtered_text)

reviewers_df['Cleaned_Review'] = reviewers_df['Checked_Review'].apply(remove_stopwords)

# Display the DataFrame with non-stop words
print(reviewers_df)

# Concatenate all cleaned reviews into a single string
all_reviews = ' '.join(reviewers_df['Cleaned_Review'])

# Generate WordCloud
wordcloud = WordCloud(width=800, height=400, max_font_size = 100, background_color='yellow').generate(text)

# Display the WordCloud 
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

#Data Engineering

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Fit and transform the target labels
encoded_labels = label_encoder.fit_transform()

# Print the original labels and their corresponding encoded values
for original_label, encoded_label in zip(targeencoded_labels):
    print(f"{original_label}: {encoded_label}")

 # Create a Tokenizer
tokenize = Tokenizer()

# Fit the tokenizer on the reviews
tokenize.fit_on_texts(reviewers_df['Cleaned_Review'])

# Convert the reviews to sequences
sequences = tokenizer.texts_to_sequences(reviewers_df['Cleaned_Review'])

# Print the tokenized sequences
print("Tokenized Sequences:")
print(sequences)

#Model Design

# Convert labels to one-hot encoded format
labels_one_hot = to_categorical(labels, num_classes=2)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    pad_sequences, 
    labels_one_hot, 
    test_size=0.2, 
    random_state=42
)

X_train = pad_sequences(X_train)
X_test = pad_sequences(X_test)
y_train = pad_sequences(y_train)
y_test = pad_sequences(y_test)

# Define the model
model = Sequential()
model.add(Embedding(input_dim=500, output_dim=120, input_length=X_train.shape[1]))
model.add(SpatialDropout1D(0.4))
model.add(LSTM(units=176, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(units=2, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Display the model summary
print(model.summary())


# Train the model
model.fit( X_train, y_train, epochs=5, batch_size=32, verbose='auto', validation_data=(X_test, y_test)) 

#Evaluate the model
predictions = model.predict(X_test)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = np.argmax(y_test, axis=1)
    
#Perform Evaluation
accuracy = accuracy_score(true_labels, predicted_labels)
print("Accuracy is:", accuracy)

print("\nClassification Report:")
print(classification_report(true_labels, predicted_labels))

report = confusion_matrix(true_labels, predicted_labels)
print("\nCorresponding Metric Evaluation:")
print(report)]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },

{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [import tkinter as tk
from tkinter import messagebox

# Your existing functions and imports
# (Assuming you have already defined remove_stopwords, tokenizer, pad_sequences, model, and maxlen)

def classify_review():
    review = entry.get()
    if review:
        cleaned_user_review = remove_stopwords(review)
        user_sequences = tokenizer.texts_to_sequences([cleaned_user_review])
        user_input_padded = pad_sequences(user_sequences, maxlen=maxlen)
        prediction_prob = model.predict(user_input_padded)[0]
        predicted_label = np.argmax(prediction_prob)

        if predicted_label == 1:
            result_label.config(text="Model Prediction: Positive review!")
        else:
            result_label.config(text="Model Prediction: Negative review.")
    else:
        messagebox.showwarning("Warning", "Please enter a review.")

# GUI setup
root = tk.Tk()
root.title("Review Classifier")

# Entry for user input
entry = tk.Entry(root, width=40)
entry.pack(pady=10)

# Button to classify review
classify_button = tk.Button(root, text="Classify Review", command=classify_review)
classify_button.pack(pady=10)

# Label to display model prediction
result_label = tk.Label(root, text="")
result_label.pack(pady=10)

# Button to exit the GUI
exit_button = tk.Button(root, text="Exit", command=root.destroy)
exit_button.pack(pady=10)

# Start the GUI main loop
root.mainloop()
]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },

  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
